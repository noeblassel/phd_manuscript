\chapter{Introduction}
\label{chap:introduction}

\section{An overview of Molecular Dynamics}
Molecular dynamics (MD) is a set of techniques aimed at extracting properties of atomistic systems from carefully designed computer simulations.
Due to the development of flexible and efficient methodologies, as well as the steady increase in available computational power over the last seventy years, MD has become a mainstay of computational physics, and is now routinely used in a variety of scientific applications from computational thermodynamics and material science to drug discovery and cell biology.
Fundamentally, MD simulates the time-evolution of systems at the atomic scale, by treating atoms as classical point particles, whose trajectories are governed by a defined set of interaction laws and dynamics. From the simulation and recording of these trajectories, several important scientific needs can be covered. Indeed, MD is simultaneously:
\begin{itemize}
\item \textit{A means to measure properties of matter}: MD provides numerical estimators for thermodynamic, structural and dynamical quantities that may be difficult or impossible to measure experimentally, due to extreme conditions or prohibitive costs. Typical outputs include radial distribution functions, free-energy differences, pressure and enthalpy, defect formation energies, reaction rates, and transport coefficients. With sufficiently long sampling, MD yields statistically converged values that can be used to parametrize coarser models. The computation of dynamical properties, and the associated need for long-time microscopic sampling, are a central motivation for Chapters~2--4.
  \item \textit{A numerical microscope}: MD simulations allows to resolve molecular trajectories at a level of detail which is far beyond the reach of physical experiments. The analysis of MD trajectories can help to visualize reaction pathways, identify transition states, observe collective rearrangements (such as nucleation, crystal defect propagation or fast protein folding), and extract mechanistic hypotheses that guide theoretical developments and experiments. These insights are especially valuable for understanding rare events and conformational changes, where a single trajectory can reveal the sequence of microscopic steps behind an observed macroscopic transition. These~\textit{in silico} experiments have become an important tool of modern research in materials science and biology.
  \item \textit{A benchmark for new methods}: due to its inherent flexibility, it is perhaps unsurprising that a major use case of MD is the development and testing of novel numerical and modelling tools for computational science at large, which in turn become useful for MD itself. New methods are validated on MD testbeds precisely because realistic atomistic models naturally combine the challenges of high dimensionality, nonlinearity and multiscale behavior.
  \item \textit{A hurdle for theory}: high-fidelity MD simulations have themselves become a source of “ground truth’’ data. Notably, long trajectories produced on bespoke hardware~\cite{SDDKLSYBBCal08} are routinely used to test biophysical hypotheses and to train data-driven models. At the same time, algorithms used in MD simulations expose some interesting mathematical questions, which are still a fruitful area of research, to which this thesis makes some contributions.
\end{itemize}
\noe{hyperrefs aux chapitres-- à ajouter}

\paragraph{Orders of magnitude}
In order to get a sense for what MD simulations can and cannot do, it is first useful to recall some characteristic scales.

\noindent
\begin{minipage}[t]{0.48\textwidth}
\textbf{Atomistic scales}
\begin{itemize}
    \item Macroscopic amounts of matter are counted in moles of molecules, which are multiples of Avogadro's number~$N_{\mathrm{A}}=6.022\times 10^{23}$.
    \item Length is measured in units of {\AA ngstr\"oms}, ($1$~\AA$\,=10^{-10}\,\mathrm{m}$). For example, the Bohr radius of hydrogen is~$0.529$~\AA, while the helix of B-DNA has a diameter of~$20$~\AA.
    \item Time is measured in units of femtoseconds,($1$\,fs$=10^{-15}$\,s), which is also the typical timestep for MD simulations. The fastest molecular vibrational periods (for instance those associated with hydrogen bond stretching modes) span the order of~$10\,\mathrm{fs}$.
\end{itemize}
\end{minipage}\hfill
\begin{minipage}[t]{0.48\textwidth}
\textbf{Computational scales}
\begin{itemize}
  \item A 2018 projection~\cite{RGR18} estimates the size of the global ``datasphere'' (the total amount of digital information on Earth) to be reach $175$~zettabytes by 2025, which corresponds to~$0.29\,N_{\mathrm{A}}$~bytes.
  \item Typical consumer machines provide on the order of~$10^{12}$~bytes of storage capacity, whereas data centers and high-performance computing facilities operate at the~$10^{15}$--$10^{18}$ bytes scale.
  \item Consumer CPUs and GPUs deliver on the order of~$10^{9}$--$10^{12}$ floating-point operations by second (FLOPS), while modern exascale machines target sustained performance around~$10^{18}$~FLOPS~\cite{Sc22}.
\end{itemize}
\end{minipage}


\paragraph{Some historical milestones.}
Despite these limitations, MD simulations have been successfully applied to various problems. A few MD simulations, notable for their historical significance, are listed below.
\begin{itemize}
    \item{\cite{MRTT53}, \cite{AWal57}}
    \item{\cite{R64}}
    \item{\cite{LW75}}
\end{itemize}
\subsection{Elements of statistical mechanics}
Statistical mechanics is the rigorous attempt to reconcile the microscopic point of view, in which a system's many microscopic degrees of freedom evolve according to fundamental physical laws, and the macroscopic point of view, according to which only a handful of variables are relevant to describe the system's state and evolution.
Here, we present the necessary formalism to treat the molecular systems of interest in MD. In particular, we restrict our scope to classical systems.
We note however that a similar Gibbsian formalism also exists for quantum systems (see~\cite{F72}) and has been more generally used to great effect in the study of a variety of disordered systems, such as spin glasses~\cite{EA75}, Hopfield networks~\cite{P84} and their quantum counterparts~\cite{RY96,RMGLM18}.

\paragraph{Microscopic states, their energy and classical dynamics.}
In this thesis, we consider systems of $N>0$ point particles, representing classical atomic nuclei.
The system's microscopic configuration, or \textit{microstate}, is described by the positions and momenta of each one of these nuclei. The microstate therefore corresponds to a point in \textit{phase space}, 
\begin{equation}
    \label{eq:01:phase_space}
    (q,p)\in \cE := \cX\times \cM,
\end{equation}
where~$\cX$ is a configurational domain, and for a configuration~$(q,p)\in\cE$, $q\in\cX$ is the position variable, and~$p\in \cM$ is the associated momentum variable in the momentum space~$\cM$.

To each microstate~$(q,p)\in\cE$, we associate its energy~$H(q,p)$. The function~$H$ is called the~\textit{Hamiltonian}. In most situations,~$\cM=\R^{3N}$, and the Hamiltonian takes the separable form
\begin{equation}
    \label{eq:01:hamiltonian}
    H(q,p) = V(q) + \frac12p^\top M^{-1}p,\qquad M = \begin{pmatrix}
    m_1 \I_3 & 0 & \dotsm & 0 \\
    0 & m_2 \I_3 & \dotsm & 0 \\
    \vdots & \ddots & \ddots & \vdots\\
    & \dotsm & 0 & m_N \I_3 
\end{pmatrix}
\end{equation}
where~$V:\cX\to\R$ is a potential energy function, the term~$\frac12p^\top M^{-1}p$ gives the kinetic energy, and~$M$ is a diagonal matrix encoding the atomic masses in the system, with~$m_i>0$ giving the mass of the~$i$-th particle for~$1\leq i\leq N$.

The classical equations of motion, as described by Newton's second law, can then be written compactly using the Hamiltonian~\eqref{eq:01:hamiltonian}. They are equivalently expressed by the following ordinary differential equation in~$\cE$:
\begin{equation}
    \label{eq:01:hamiltonian_dynamics}
    \frac{\d}{\d t}\,X_t = -J\nabla H(X_t),\qquad X_t = (q_t,p_t)\in \cE,
\end{equation}
where~$J$ is the antisymmetric matrix
\begin{equation}
    \label{eq:01:J}
    J=\begin{pmatrix}
        0&\I_{3N}\\-\I_{3N}&0
    \end{pmatrix}.
\end{equation}
In this form, the equation~\eqref{eq:01:hamiltonian_dynamics} is commonly known as~\textit{Hamiltonian dynamics}, and its trajectories in phase space describe the time-evolution of an isolated system of classical particles.

\paragraph{On the choice of the interaction potential~$V$.}
The potential~$V$ is the crucial physical parameter, since it encodes the interactions between nuclei, and therefore their dynamics. Ideally, it is defined by the ground-state energy of the electronic Schr\"odinger operator in the Borne--Oppenheimer approximation~\cite{BO27}:
\begin{equation}
    \label{eq:01:schrodinger}
    V_{\mathrm{BO}}(q) = \inf\left\{\left\langle\psi, H(q) \psi\right\rangle_{\mathcal H_\cX}:\,\psi \in \mathcal H^1_{\cX,q},\,\|\psi\|_{\mathcal H_\cX}=1\right\},
\end{equation}
where~$\mathcal H_{\cX}$ and~$H(q)$ are respectively the Hilbert space of electronic wave functions and the electronic Hamiltonian associated with a given position configuration of nuclei~$q\in\cX$, with form domain~$\mathcal H^1_{\cX,q}\subset \mathcal H_{\cX}$.

However, for systems of interest in MD, the problem~\eqref{eq:01:schrodinger}, being a high-dimensional partial differential equation (PDE) eigenvalue problem, cannot be solved directly. Instead, one resorts to a variety of approximations.
\begin{itemize}
    \item{\textit{Ab initio potentials}: very precise, but limited to small systems/short timescales}
    \item{\textit{Empirical potentials}: historical importance, functional form of the AMBER family}
    \item{\textit{Machine learning force fields}: able to reach close to ab initio accuracy, but may suffer from generalizability issues}
\end{itemize}

\paragraph{Boundary conditions.}
The specific definition of the phase space~$\cE$ depends on the physical model and properties of interest. We distinguish several common choices,  listed here in approximate order of frequency of use in MD simulations.
\begin{itemize}
    \item{\textit{Periodic boundary conditions}: this common choice corresponds to setting~$\cX = (L\T)^d$ and~$\cM=\R^d$, where~$\T=\R/\Z$ is the unit one-dimensional torus,~$d=3N$ is the number of position degrees of freedom in the system, and~$L>0$ is a length parameter fixing the size of the domain. This setup is essential for studying the bulk properties of matter, as the periodic unit cell models a small portion of the molecular medium while its images represent the surrounding environment, eliminating surface effects.}
    \item{\textit{Non-flat position manifolds}: for certain applications, it is useful to restrict the particle positions to a non-flat manifold~$\cX$. This can be useful for enforcing geometric constraints, such as fixed bond length or angles, or for expressing the equations of motion in non-Cartesian coordinates~\cite{VJ15}. Such constraints can improve the stability of numerical schemes~\cite{RCB77,A83,BKLS95}, allowing for larger time steps, and can be used for computing free energy differences~\cite{SC98,LRS12}. In this geometric setting, the momentum associated to a given position~$q\in\cX$ is a cotangent vector~$p\in T_q^*\cX$, and the phase space~$\cE$ is the cotangent bundle:~$\cE=T^*\cX$.}
    \item{\textit{Unbounded domains}: setting~$\cX$ and~$\cM$ equal to~$\R^d$ is appropriate for studying molecular systems in isolation, such as small atomic clusters or single molecules in vacuum.}
    \item{\textit{Exotic boundary conditions}: for the purpose of some specialized simulations, one can consider a variety of additional boundary conditions. For instance, one can consider walls at the boundary of a domain~$\partial\cX$, on which particles are subject to specular or diffuse reflections, or absorption~(the case of absorbing boundaries is considered in Chapters~2 and~3 of this thesis). Mixed conditions, which are periodic with respect to a subset of coordinates, can be used to study interfaces. One can even consider time-dependent definitions, such as Lees--Edwards boundary conditions~\cite{LE72}, which allow to study shear flows.}
\end{itemize}

\paragraph{Statistical ensembles.}
The basic postulate of statistical mechanics, as formalized by Gibbs in~\cite{G02}, is that the system's macroscopic configuration is a probability distribution~${\pi\in\cP(\cE)}$ over the set of possible microstates.
The distribution~$\pi$ is also known as a statistical or~\textit{thermodynamic ensemble}. In this statistical description, the ensemble~$\pi$ assigns to each microstate the likelihood of underlying the observed macrostate, and is therefore a crucial model parameter.

Given a physical observable~$\varphi:\cE\to\R$, we can then define the macroscopic value of~$\varphi$ as the~\textit{ensemble average}:
\begin{equation}
    \label{eq:01:ensemble_average}
    \langle \varphi\rangle_{\pi} = \E_\pi\left[\varphi\right]= \int_{\cE}\varphi\,\d \pi.
\end{equation}

To make the description operational, one should seek a principled way to assign a specific ensemble to a given set of physical conditions.
We distinguish two families of methods to satisfy this goal.

\begin{itemize}
    \item{\textit{Dynamical definitions}. In these constructions, the ensemble~$\pi$ is identified with an invariant probability measure or~\textit{steady state} of the system's underlying dynamics.
    Whether the dynamics are deterministic or stochastic, whenever the system is ergodic with respect to~$\pi$, time averages of observables along a single, long trajectory will converge to the ensemble average~\eqref{eq:01:ensemble_average}.
    This approach provides a physical justification for the ensemble by connecting it directly to the microscopic time-evolution of the system, in the case a model of the microscopic dynamics is available.
    It also the viewpoint which constitutes the theoretical underpinning the computation of thermodynamic quantities in equilibrium and nonequilibrium molecular dynamics.
    }
    \item{Variational definitions based on the \textit{principle of maximal entropy}, as described in \cite{J57a,J57b}, offer a fairly general alternative.
    This approach frames the problem of determining the ensemble from the knowledge of macroscopic data as a problem of statistical inference.
    Namely, the ensemble~$\pi$ is defined as the probability distribution which maximizes the information entropy, given by the ensemble average $S[\pi] = -\langle\log\pi\rangle_\pi$ (with some abuse of notation), subject to a set of constraints derived from the observation of the values of a number of macroscopic variables.
    Informally, this principle selects the most uninformative distribution compatible with the available information, and draws a connection between statistical mechanics and information theory. Solving for~$\pi$ generally leads to explicit expressions, regardless of existence of some ergodic microscopic dynamics.}
\end{itemize}

\paragraph{Examples of statistical ensembles.}
We now give some examples, the first two of which were introduced by Gibbs in~\cite{G02}, and are of primary interest for MD.
\begin{itemize}
    \item{\textit{The microcanonical ensemble} ($NVE$) describes an isolated system with a fixed number of particles ($N$), volume ($V$), and total energy ($E$). It is given by the probability measure~$\mu_{NVE}$, where
    \begin{equation}
        \label{eq:01:microcanonical_distribution}
        \forall\,A\in\mathcal B(\cE),\qquad \mu_{NVE}(A) = \frac1{Z_{NVE}}\int_{A\cap H^{-1}(E)}|\nabla H|^{-1}\d\mathcal{H}_{H^{-1}(E)},
    \end{equation}
    where~$\mathcal{H}_{H^{-1}(E)}$ is the~$(d-1)$-dimensional Hausdorff measure on the constant-energy surface~$H^{-1}(E)$ and
    \[Z_{NVE}=\int_{H^{-1}(E)}|\nabla H|^{-1}\d\mathcal{H}_{H^{-1}(E)}\]
    is a normalizing constant known as the~\textit{microcanonical partition function}. Dynamically, it is the invariant measure of Hamiltonian dynamics~\eqref{eq:01:hamiltonian_dynamics} started at a point~$X_0\in H^{-1}(E)$, assuming the ergodic hypothesis. The measure~$\mu_{NVE}$ can also be viewed as the limit as~$\delta\to 0$ of uniform probability distributions on the energy shells~$S(E,\delta):=H^{-1}(E-\delta,E+\delta)$, which are well-known to maximize the information entropy in~$\cP(S(E,\delta))$ whenever~$S(E,\delta)$ is compact.}

    \item{\textit{The canonical ensemble} ($NVT$) describes a system with fixed number of particles and volume, in thermal equilibrium with a heat bath at a constant temperature $T$. It is given by the \textit{Boltzmann--Gibbs distribution}
    \begin{equation}
        \label{eq:01:boltzmann_gibbs}
        \forall\,A\in\mathcal B(\cE),\qquad \mu(A) = \frac{1}{Z_{NVT}(\beta)}\int_{A}\e^{-\beta H(q,p)}\,\d q\,\d p,
    \end{equation}
    where~$H$ is defined in~\eqref{eq:01:hamiltonian},~$\beta = (k_{\mathrm{B}}T)^{-1}$,~$k_{\mathrm{B}}$ is Boltzmann's constant and
    \[
    Z_{NVT}(\beta) = \int_{\cE}\e^{-\beta H(q,p)}\,\d q\,\d p
    \]
    is the~\textit{canonical partition function}.
    It correspond to invariant probability measure for a system evolving under various stochastic dynamics (some of which are discussed in Section~\ref{subsec:01:sampling} below) which model the interaction with the heat bath. From the point of view of the maximum entropy principle, it is derived by maximizing the information entropy subject to the constraint of a fixed \textit{average} energy, which is related to the temperature $T$ by the formula~${\langle H\rangle_\mu = -\frac{\partial}{\partial\beta}Z_{NVT}(\beta)}$. }
    \item{Other equilibrium ensembles can be constructed to model more general physical conditions. The \textit{isothermal-isobaric ensemble} ($NPT$) describes systems at constant temperature and pressure~$P$, which are sometimes relevant for biological applications, and is derived from the maximal entropy principle by fixing the average energy and average volume of the system (related to the pressure~$P$). The \textit{grand-canonical ensemble} ($\mu$VT) describes systems that can exchange both heat and particles with a bath, and is defined by fixing the average energy and average particle number (related to the chemical potential $\mu$).}
    \item{\textit{Nonequilibrium ensembles}, describe systems driven away from thermal equilibrium by the application of non-conservative forces or thermal gradients. These systems are characterized by the presence of irreversible fluxes and entropy production. Most often, these ensembles are defined dynamically, as the invariant measure of some nonequilibrium process, in which case the ensemble is also known as a nonequilibrium steady-states~(NESS). The question of finding variational constructions for nonequilibrium ensembles has been investigated in the physical literature~(see~\cite{J80}), but does not appear to be fully settled at this time.}
\end{itemize}
Finally, let us mention that \textit{equivalence of ensembles} results allow to relate averages in one ensemble to averages in another. For instance, it has been shown that, for systems with short-range interactions, the~$NVE$ and~$NVE$ ensembles are equivalent (on several levels, see~\cite{T15}) in the thermodynamic limit~$N,V\to +\infty$ keeping the particle density~$\rho = N/V$ fixed.
Such an equivalence implies in particular that~$\langle\varphi\rangle_{NVT} \approx \langle \varphi\rangle_{NVE}$ when~$N$ is large and~$T$ is chosen such that~$\langle H\rangle_{NVT}=E$.
An example of equivalence for nonequilibrium ensembles is discussed in~\cite{CT13}.

\subsection{Sampling equilibrium properties}
\label{subsec:01:sampling}
\paragraph{Langevin dynamics.}
- Formula for underdamped Langevin dynamics
- Historical reference of derivation from coupled oscillators (Ford, Kac, Mazur)
- Use for sampling Boltzmann--Gibbs
- Overdamped limit

\paragraph{More general families of stochastic dynamics.}
- More general diffusion and frictions coefficients
- Generalized Langevin dynamics and Mori--Zwanzig formalism

\subsection{Dynamical properties}
- Reaction rates
- Transport coefficients

\subsection{Challenges}
- Metastability and the timescale problems

\section{Mathematical approaches to the problem of metastability}
\subsection{Global descriptions}
\subsection{Local descriptions}
\subsection{Numerical methods}

\section{Main contributions of this thesis}
\paragraph{On the mathematical study of metastability}
\paragraph{Accelerated MD methodology}
\paragraph{Nonequilibrium sampling}


